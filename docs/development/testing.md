# Tests & Couverture ‚Äî Module 3 : Future Skills

## 1. Outil de couverture

Pour mesurer la qualit√© des tests du Module 3, nous utilisons **coverage.py**.

- Installation dans l'environnement virtuel :

  ```bash
  pip install coverage
  ```

- Fichier de configuration √† la racine du projet : `.coveragerc` :

  ```ini
  [run]
  source = future_skills
  branch = True

  [report]
  omit =
      */migrations/*
      */tests/*
      config/*
  show_missing = True
  ```

## 2. Commandes utilis√©es

Pour ex√©cuter les tests du Module 3 avec mesure de couverture :

```bash
coverage run manage.py test future_skills
coverage report
```

(Optionnel) Pour g√©n√©rer un rapport HTML d√©taill√© :

```bash
coverage html
```

Le rapport est ensuite consultable via `htmlcov/index.html`.

## 3. R√©sultats de couverture (Module 3 ‚Äî Future Skills)

**R√©sultat au : 26/11/2025**

- **Couverture globale du module `future_skills` : 78 %**

**D√©tails par fichier :**

- `future_skills/serializers.py` : **100 %** ‚úÖ
- `future_skills/services/recommendation_engine.py` : **100 %** ‚úÖ
- `future_skills/services/prediction_engine.py` : **91 %** ‚úÖ
- `future_skills/models.py` : **92 %** ‚úÖ
- `future_skills/permissions.py` : **90 %** ‚úÖ
- `future_skills/admin.py` : **81 %** ‚úÖ
- `future_skills/views.py` : **55 %** ‚ö†Ô∏è

**Fichiers non couverts (exclus des statistiques) :**

- `future_skills/management/commands/recalculate_future_skills.py` : 0 % (commande CLI)
- `future_skills/management/commands/seed_future_skills.py` : 0 % (commande CLI)

**Analyse :**

- ‚úÖ Les composants critiques (services, mod√®les, permissions) ont une excellente couverture (> 90%)
- ‚úÖ La logique m√©tier est bien test√©e
- ‚ö†Ô∏è Les vues API pourraient b√©n√©ficier de tests suppl√©mentaires
- ‚ÑπÔ∏è Les commandes de management ne n√©cessitent pas de tests unitaires (usage CLI ponctuel)

Le rapport HTML d√©taill√© est disponible dans `htmlcov/index.html`.

## 4. Types de tests

### 4.1 Tests unitaires

- **Moteur de pr√©diction** (`test_prediction_engine.py`) : Validation des algorithmes de pr√©diction
- **Moteur de recommandations** (`test_recommendations.py`) : Validation de la logique de recommandations RH

### 4.2 Tests d'API

- **Endpoints REST** (`test_api.py`) : Tests des vues et endpoints du module Future Skills
- Validation des permissions et autorisations
- Tests des formats de r√©ponse et codes HTTP

## 5. D√©marche qualit√©

Le Module 3 respecte une d√©marche qualit√© "production" :

- ‚úÖ Tests unitaires pour la logique m√©tier
- ‚úÖ Tests d'int√©gration pour les API
- ‚úÖ Mesure de couverture avec coverage.py
- ‚úÖ Tra√ßabilit√© et documentation

## 6. R√©sum√© des r√©sultats

| M√©trique                | Valeur      | Statut         |
| ----------------------- | ----------- | -------------- |
| **Tests ex√©cut√©s**      | 12 tests    | ‚úÖ Tous pass√©s |
| **Couverture globale**  | 78 %        | ‚úÖ Bon         |
| **Couverture services** | 91-100 %    | ‚úÖ Excellent   |
| **Couverture mod√®les**  | 92 %        | ‚úÖ Excellent   |
| **Temps d'ex√©cution**   | ~4 secondes | ‚úÖ Rapide      |

### Points forts

- üéØ Excellente couverture des composants critiques (services, mod√®les)
- üéØ Tests bien structur√©s (unitaires + API)
- üéØ Configuration coverage.py optimis√©e
- üéØ Tous les tests passent sans erreur

### Axes d'am√©lioration (optionnel)

- üìà Augmenter la couverture des vues API (actuellement 55%)
- üìà Ajouter des tests pour les cas limites suppl√©mentaires

---

**Conclusion :** Le Module 3 dispose d'une couverture de tests solide et respecte les standards de qualit√© pour une mise en production.

---

## 7. Tests de l'int√©gration Machine Learning (ML-3)

### 7.1 Contexte

Le Module 3 int√®gre un mod√®le de Machine Learning optionnel pour la pr√©diction des comp√©tences futures. Les tests doivent garantir que :

1. Le syst√®me fonctionne correctement quand le mod√®le ML est disponible
2. Le syst√®me bascule automatiquement sur le moteur de r√®gles (fallback) si le mod√®le est indisponible
3. La tra√ßabilit√© via `PredictionRun` refl√®te fid√®lement le moteur utilis√©

### 7.2 Commandes de test

**Ex√©cuter tous les tests du Module 3 :**
```bash
python manage.py test future_skills
```

**Ex√©cuter les tests avec couverture :**
```bash
coverage run manage.py test future_skills
coverage report
```

**G√©n√©rer un rapport HTML d√©taill√© :**
```bash
coverage html
# Ouvrir htmlcov/index.html dans un navigateur
```

**Ex√©cuter uniquement les tests ML/fallback :**
```bash
python manage.py test future_skills.tests.test_prediction_engine.MLFallbackTests
python manage.py test future_skills.tests.test_api.RecalculateFutureSkillsMLFallbackTests
```

### 7.3 Aspects couverts par les tests ML

| Aspect test√©                              | Fichier de test                    | Classe/M√©thode                                    |
|-------------------------------------------|------------------------------------|---------------------------------------------------|
| Moteur de r√®gles fonctionne normalement   | `test_prediction_engine.py`        | `CalculateLevelTests`                             |
| Fallback ML ‚Üí r√®gles si `.pkl` absent     | `test_prediction_engine.py`        | `MLFallbackTests.test_fallback_to_rules_when_ml_unavailable` |
| Utilisation effective du ML si disponible | `test_prediction_engine.py`        | `MLFallbackTests.test_uses_ml_when_available`     |
| API fallback avec ML indisponible         | `test_api.py`                      | `RecalculateFutureSkillsMLFallbackTests.test_recalculate_with_ml_unavailable_fallback_to_rules` |
| Tra√ßabilit√© `PredictionRun.parameters`    | `test_prediction_engine.py`, `test_api.py` | V√©rification du champ `engine` dans tous les tests |

### 7.4 Strat√©gies de test utilis√©es

**1. Override de settings avec `@override_settings` :**
```python
from django.test import override_settings

@override_settings(FUTURE_SKILLS_USE_ML=True)
def test_ml_behavior(self):
    # Test avec flag ML activ√©
    ...
```

**2. Mock du mod√®le ML :**
```python
from unittest.mock import patch

@patch("future_skills.services.prediction_engine.FutureSkillsModel.instance")
def test_fallback(self, mock_ml_instance):
    mock_ml_instance.return_value.is_available.return_value = False
    # Le syst√®me doit utiliser le fallback
    ...
```

**3. V√©rification de tra√ßabilit√© :**
```python
last_run = PredictionRun.objects.order_by("-run_date").first()
self.assertEqual(last_run.parameters["engine"], "rules_v1")
```

### 7.5 R√©sultats attendus

Tous les tests ML doivent passer avec succ√®s :

```
‚úì test_fallback_to_rules_when_ml_unavailable ... ok
‚úì test_uses_ml_when_available ... ok
‚úì test_recalculate_with_ml_unavailable_fallback_to_rules ... ok
```

**Couverture cible :**
- `prediction_engine.py` : > 90%
- `ml_model.py` : > 85%
- Vues API : > 70%

### 7.6 Cas limites test√©s

- ‚úÖ Fichier `.pkl` absent
- ‚úÖ Fichier `.pkl` corrompu (via mock)
- ‚úÖ Flag `FUTURE_SKILLS_USE_ML` d√©sactiv√©
- ‚úÖ Tra√ßabilit√© avec utilisateur authentifi√© (API)
- ‚úÖ Tra√ßabilit√© sans utilisateur (commande CLI)
- ‚úÖ Coh√©rence des labels LOW/MEDIUM/HIGH entre moteurs

### 7.7 CI/CD et automatisation

Les tests ML sont int√©gr√©s dans le pipeline CI/CD :

```bash
# Dans le script CI
python manage.py test future_skills --parallel --keepdb
coverage run manage.py test future_skills
coverage report --fail-under=75
```

**Seuil de couverture minimum :** 75% pour l'ensemble du module.

---

**Conclusion ML-3 :** Les tests ML garantissent la robustesse du syst√®me de pr√©diction en conditions r√©elles, avec ou sans mod√®le ML disponible, et assurent une tra√ßabilit√© compl√®te pour l'audit et la conformit√©.
