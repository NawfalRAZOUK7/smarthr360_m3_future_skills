name: CD - Deploy to Staging

on:
  push:
    branches: [develop]
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy to"
        required: true
        default: "staging"
        type: choice
        options:
          - staging
          - dev

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    # Note: Create 'staging' environment in GitHub Settings > Environments
    # before using this workflow (no approvers needed for staging)
    environment:
      name: staging
      url: https://staging.smarthr360.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.28.0"

      - name: Configure AWS credentials
        if: env.CLOUD_PROVIDER == 'aws'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig (AWS EKS)
        if: env.CLOUD_PROVIDER == 'aws'
        run: |
          aws eks update-kubeconfig \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --region ${{ secrets.AWS_REGION }}
        env:
          CLOUD_PROVIDER: ${{ secrets.CLOUD_PROVIDER }}

      - name: Configure GCP credentials
        if: env.CLOUD_PROVIDER == 'gcp'
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Update kubeconfig (GKE)
        if: env.CLOUD_PROVIDER == 'gcp'
        run: |
          gcloud container clusters get-credentials \
            ${{ secrets.GKE_CLUSTER_NAME }} \
            --zone ${{ secrets.GCP_ZONE }} \
            --project ${{ secrets.GCP_PROJECT }}
        env:
          CLOUD_PROVIDER: ${{ secrets.CLOUD_PROVIDER }}

      - name: Configure Azure credentials
        if: env.CLOUD_PROVIDER == 'azure'
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Update kubeconfig (AKS)
        if: env.CLOUD_PROVIDER == 'azure'
        run: |
          az aks get-credentials \
            --name ${{ secrets.AKS_CLUSTER_NAME }} \
            --resource-group ${{ secrets.AZURE_RESOURCE_GROUP }}
        env:
          CLOUD_PROVIDER: ${{ secrets.CLOUD_PROVIDER }}

      - name: Create namespace if not exists
        run: |
          kubectl create namespace smarthr360-staging --dry-run=client -o yaml | kubectl apply -f -

      - name: Create/Update secrets
        run: |
          # Create Docker registry secret
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=${{ env.REGISTRY }} \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GITHUB_TOKEN }} \
            --namespace=smarthr360-staging \
            --dry-run=client -o yaml | kubectl apply -f -

          # Create application secrets
          kubectl create secret generic smarthr360-secrets \
            --from-literal=SECRET_KEY="${{ secrets.DJANGO_SECRET_KEY }}" \
            --from-literal=JWT_SECRET_KEY="${{ secrets.JWT_SECRET_KEY }}" \
            --from-literal=DB_PASSWORD="${{ secrets.STAGING_DB_PASSWORD }}" \
            --from-literal=DB_USER="${{ secrets.STAGING_DB_USER }}" \
            --from-literal=REDIS_PASSWORD="${{ secrets.STAGING_REDIS_PASSWORD }}" \
            --from-literal=ELASTIC_APM_SECRET_TOKEN="${{ secrets.ELASTIC_APM_SECRET_TOKEN }}" \
            --from-literal=SENTRY_DSN="${{ secrets.SENTRY_DSN }}" \
            --namespace=smarthr360-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Update image tags in manifests
        run: |
          cd k8s/overlays/staging

          # Update kustomization with new image tags
          kustomize edit set image \
            smarthr360-api=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api:${{ github.sha }} \
            smarthr360-celery=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-celery:${{ github.sha }} \
            smarthr360-nginx=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-nginx:${{ github.sha }}

      - name: Deploy to Kubernetes
        run: |
          # Apply manifests using kustomize
          kubectl apply -k k8s/overlays/staging

          # Wait for rollout to complete
          kubectl rollout status deployment/smarthr360-api -n smarthr360-staging --timeout=5m
          kubectl rollout status deployment/smarthr360-celery-worker -n smarthr360-staging --timeout=5m
          kubectl rollout status deployment/smarthr360-celery-beat -n smarthr360-staging --timeout=5m

      - name: Run database migrations
        run: |
          # Get API pod name
          API_POD=$(kubectl get pod -n smarthr360-staging -l component=api -o jsonpath='{.items[0].metadata.name}')

          # Run migrations
          kubectl exec -n smarthr360-staging $API_POD -- python manage.py migrate --noinput

          # Collect static files
          kubectl exec -n smarthr360-staging $API_POD -- python manage.py collectstatic --noinput

      - name: Verify deployment
        run: |
          # Check pod status
          kubectl get pods -n smarthr360-staging

          # Check service endpoints
          kubectl get svc -n smarthr360-staging

          # Test health endpoint
          INGRESS_IP=$(kubectl get ingress -n smarthr360-staging -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}')
          if [ -n "$INGRESS_IP" ]; then
            curl -f http://$INGRESS_IP/api/health/ || echo "Health check failed"
          fi

      - name: Run smoke tests
        run: |
          # Port-forward for testing
          kubectl port-forward -n smarthr360-staging svc/smarthr360-api 8000:8000 &
          PF_PID=$!

          sleep 5

          # Test endpoints
          curl -f http://localhost:8000/api/health/ || exit 1
          curl -f http://localhost:8000/api/skills/ || exit 1

          # Cleanup
          kill $PF_PID

      - name: Update deployment status
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ Deployment to staging successful"
            echo "üîó URL: https://staging.smarthr360.com"
          else
            echo "‚ùå Deployment to staging failed"
          fi

      - name: Rollback on failure
        if: failure()
        run: |
          echo "Rolling back deployment..."
          kubectl rollout undo deployment/smarthr360-api -n smarthr360-staging
          kubectl rollout undo deployment/smarthr360-celery-worker -n smarthr360-staging
          kubectl rollout undo deployment/smarthr360-celery-beat -n smarthr360-staging

      - name: Send deployment notification
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            üöÄ Staging Deployment ${{ job.status }}
            Environment: staging
            Version: ${{ github.sha }}
            URL: https://staging.smarthr360.com
            Triggered by: ${{ github.actor }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
