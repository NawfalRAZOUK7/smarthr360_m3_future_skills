{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e889541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Configuration du style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aaf6f4",
   "metadata": {},
   "source": [
    "## 1. Chargement du mod√®le et du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins\n",
    "BASE_DIR = Path().resolve()\n",
    "MODEL_PATH = BASE_DIR / \"future_skills_model.pkl\"\n",
    "DATASET_PATH = BASE_DIR / \"future_skills_dataset.csv\"\n",
    "\n",
    "# V√©rification\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Mod√®le introuvable: {MODEL_PATH}\")\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset introuvable: {DATASET_PATH}\")\n",
    "\n",
    "print(f\"üìÇ Mod√®le: {MODEL_PATH}\")\n",
    "print(f\"üìÇ Dataset: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le pipeline\n",
    "pipeline = joblib.load(MODEL_PATH)\n",
    "print(f\"‚úÖ Mod√®le charg√©: {type(pipeline).__name__}\")\n",
    "print(f\"   √âtapes: {list(pipeline.named_steps.keys())}\")\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(f\"\\n‚úÖ Dataset charg√©: {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "print(f\"   Colonnes: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les niveaux valides\n",
    "ALLOWED_LEVELS = {\"LOW\", \"MEDIUM\", \"HIGH\"}\n",
    "df = df[df[\"future_need_level\"].isin(ALLOWED_LEVELS)].copy()\n",
    "\n",
    "print(f\"üìä R√©partition des classes:\")\n",
    "print(df[\"future_need_level\"].value_counts())\n",
    "print(f\"\\nüìä Pourcentages:\")\n",
    "print(df[\"future_need_level\"].value_counts(normalize=True).mul(100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffce826",
   "metadata": {},
   "source": [
    "## 2. Pr√©paration des donn√©es pour l'explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba509cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les features disponibles\n",
    "potential_features = [\n",
    "    \"job_role_name\",\n",
    "    \"skill_name\",\n",
    "    \"skill_category\",\n",
    "    \"job_department\",\n",
    "    \"trend_score\",\n",
    "    \"internal_usage\",\n",
    "    \"training_requests\",\n",
    "    \"scarcity_index\",\n",
    "    \"hiring_difficulty\",\n",
    "    \"avg_salary_k\",\n",
    "    \"economic_indicator\",\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in potential_features if col in df.columns]\n",
    "target_col = \"future_need_level\"\n",
    "\n",
    "print(f\"‚úÖ Features utilis√©es ({len(feature_cols)}):\")\n",
    "for col in feature_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d860969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©parer features cat√©gorielles et num√©riques\n",
    "categorical_features = []\n",
    "numeric_features = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "        categorical_features.append(col)\n",
    "    else:\n",
    "        numeric_features.append(col)\n",
    "\n",
    "print(f\"üìã Features cat√©gorielles: {categorical_features}\")\n",
    "print(f\"üìã Features num√©riques: {numeric_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb5fe36",
   "metadata": {},
   "source": [
    "## 3. S√©lection d'exemples repr√©sentatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18366776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner 2 exemples HIGH et 2 exemples MEDIUM\n",
    "high_examples = df[df[\"future_need_level\"] == \"HIGH\"].sample(n=min(2, len(df[df[\"future_need_level\"] == \"HIGH\"])), random_state=42)\n",
    "medium_examples = df[df[\"future_need_level\"] == \"MEDIUM\"].sample(n=min(2, len(df[df[\"future_need_level\"] == \"MEDIUM\"])), random_state=42)\n",
    "\n",
    "examples = pd.concat([high_examples, medium_examples])\n",
    "\n",
    "print(f\"üéØ Exemples s√©lectionn√©s pour l'analyse:\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "for idx, row in examples.iterrows():\n",
    "    print(f\"\\nüìå Exemple {idx}:\")\n",
    "    print(f\"   Job Role: {row.get('job_role_name', 'N/A')}\")\n",
    "    print(f\"   Skill: {row.get('skill_name', 'N/A')}\")\n",
    "    print(f\"   Level: {row['future_need_level']}\")\n",
    "    print(f\"   Trend Score: {row.get('trend_score', 'N/A')}\")\n",
    "    print(f\"   Internal Usage: {row.get('internal_usage', 'N/A')}\")\n",
    "    print(f\"   Scarcity Index: {row.get('scarcity_index', 'N/A')}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e9f0",
   "metadata": {},
   "source": [
    "## 4. SHAP Analysis\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est bas√© sur la th√©orie des jeux et fournit des explications coh√©rentes et interpr√©tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccfb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les donn√©es transform√©es pour SHAP\n",
    "# Le pipeline contient un preprocessor + classifier\n",
    "preprocessor = pipeline.named_steps['preprocess']\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "# Transformer toutes les donn√©es\n",
    "X_transformed = preprocessor.transform(X)\n",
    "\n",
    "# Pour les exemples s√©lectionn√©s\n",
    "X_examples = examples[feature_cols]\n",
    "X_examples_transformed = preprocessor.transform(X_examples)\n",
    "\n",
    "print(f\"‚úÖ Donn√©es transform√©es: {X_transformed.shape}\")\n",
    "print(f\"‚úÖ Exemples transform√©s: {X_examples_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un explainer SHAP pour RandomForest\n",
    "# TreeExplainer est optimal pour les mod√®les bas√©s sur les arbres\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "# Calculer les valeurs SHAP pour nos exemples\n",
    "shap_values = explainer.shap_values(X_examples_transformed)\n",
    "\n",
    "print(f\"‚úÖ SHAP values calcul√©es\")\n",
    "print(f\"   Shape: {shap_values[0].shape if isinstance(shap_values, list) else shap_values.shape}\")\n",
    "print(f\"   Classes: {clf.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les noms des features apr√®s transformation\n",
    "feature_names = []\n",
    "\n",
    "# Features cat√©gorielles (OneHot encoded)\n",
    "if categorical_features:\n",
    "    cat_transformer = preprocessor.named_transformers_['cat']\n",
    "    if hasattr(cat_transformer, 'get_feature_names_out'):\n",
    "        cat_names = cat_transformer.get_feature_names_out(categorical_features)\n",
    "        feature_names.extend(cat_names)\n",
    "\n",
    "# Features num√©riques\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "print(f\"‚úÖ {len(feature_names)} feature names apr√®s transformation\")\n",
    "print(f\"   Premi√®res 10: {feature_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation SHAP: Force plots pour chaque exemple\n",
    "shap.initjs()\n",
    "\n",
    "for i, (idx, row) in enumerate(examples.iterrows()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä SHAP Force Plot - Exemple {i+1}\")\n",
    "    print(f\"   Job Role: {row.get('job_role_name', 'N/A')}\")\n",
    "    print(f\"   Skill: {row.get('skill_name', 'N/A')}\")\n",
    "    print(f\"   True Level: {row['future_need_level']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Pr√©diction\n",
    "    pred = clf.predict(X_examples_transformed[i:i+1])[0]\n",
    "    pred_proba = clf.predict_proba(X_examples_transformed[i:i+1])[0]\n",
    "    \n",
    "    print(f\"   Predicted: {pred}\")\n",
    "    for j, cls in enumerate(clf.classes_):\n",
    "        print(f\"   P({cls}): {pred_proba[j]:.3f}\")\n",
    "    \n",
    "    # Force plot pour la classe pr√©dite\n",
    "    predicted_class_idx = np.argmax(pred_proba)\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Multi-class: une matrice par classe\n",
    "        shap_display = shap.force_plot(\n",
    "            explainer.expected_value[predicted_class_idx],\n",
    "            shap_values[predicted_class_idx][i],\n",
    "            X_examples_transformed[i],\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "    else:\n",
    "        # Binary\n",
    "        shap_display = shap.force_plot(\n",
    "            explainer.expected_value,\n",
    "            shap_values[i],\n",
    "            X_examples_transformed[i],\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "    \n",
    "    display(shap_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d7b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plots (mieux pour visualiser individuellement)\n",
    "for i, (idx, row) in enumerate(examples.iterrows()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä SHAP Waterfall Plot - Exemple {i+1}: {row.get('job_role_name', 'N/A')} √ó {row.get('skill_name', 'N/A')}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    pred_proba = clf.predict_proba(X_examples_transformed[i:i+1])[0]\n",
    "    predicted_class_idx = np.argmax(pred_proba)\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        shap_obj = shap.Explanation(\n",
    "            values=shap_values[predicted_class_idx][i],\n",
    "            base_values=explainer.expected_value[predicted_class_idx],\n",
    "            data=X_examples_transformed[i],\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "    else:\n",
    "        shap_obj = shap.Explanation(\n",
    "            values=shap_values[i],\n",
    "            base_values=explainer.expected_value,\n",
    "            data=X_examples_transformed[i],\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.waterfall_plot(shap_obj, max_display=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot: vue d'ensemble de l'importance des features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SHAP Summary Plot - Vue d'ensemble\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    # Pour chaque classe\n",
    "    for class_idx, class_name in enumerate(clf.classes_):\n",
    "        print(f\"\\nüéØ Classe: {class_name}\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values[class_idx],\n",
    "            X_examples_transformed,\n",
    "            feature_names=feature_names,\n",
    "            show=False,\n",
    "            max_display=10\n",
    "        )\n",
    "        plt.title(f\"SHAP Summary - {class_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        X_examples_transformed,\n",
    "        feature_names=feature_names,\n",
    "        show=False,\n",
    "        max_display=10\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba37a3",
   "metadata": {},
   "source": [
    "## 5. LIME Analysis (Alternative)\n",
    "\n",
    "LIME fournit des explications locales en approximant le mod√®le par un mod√®le lin√©aire simple autour de l'instance √† expliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18689d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er l'explainer LIME\n",
    "# Utiliser un √©chantillon du dataset pour d√©finir l'espace des features\n",
    "sample_size = min(1000, len(X_transformed))\n",
    "X_sample = X_transformed[:sample_size]\n",
    "\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=X_sample,\n",
    "    feature_names=feature_names,\n",
    "    class_names=clf.classes_,\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LIME Explainer cr√©√©\")\n",
    "print(f\"   Training samples: {sample_size}\")\n",
    "print(f\"   Features: {len(feature_names)}\")\n",
    "print(f\"   Classes: {clf.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer des explications LIME pour chaque exemple\n",
    "for i, (idx, row) in enumerate(examples.iterrows()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä LIME Explanation - Exemple {i+1}\")\n",
    "    print(f\"   Job Role: {row.get('job_role_name', 'N/A')}\")\n",
    "    print(f\"   Skill: {row.get('skill_name', 'N/A')}\")\n",
    "    print(f\"   True Level: {row['future_need_level']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # G√©n√©rer l'explication\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        data_row=X_examples_transformed[i],\n",
    "        predict_fn=clf.predict_proba,\n",
    "        num_features=10,\n",
    "        top_labels=3\n",
    "    )\n",
    "    \n",
    "    # Afficher l'explication\n",
    "    pred = clf.predict(X_examples_transformed[i:i+1])[0]\n",
    "    print(f\"   Predicted: {pred}\")\n",
    "    \n",
    "    # Probabilit√©s\n",
    "    pred_proba = clf.predict_proba(X_examples_transformed[i:i+1])[0]\n",
    "    for j, cls in enumerate(clf.classes_):\n",
    "        print(f\"   P({cls}): {pred_proba[j]:.3f}\")\n",
    "    \n",
    "    # Visualisation\n",
    "    print(\"\\n   Top contributing features:\")\n",
    "    predicted_class_idx = np.argmax(pred_proba)\n",
    "    for feat, weight in exp.as_list(label=predicted_class_idx)[:10]:\n",
    "        print(f\"     {feat}: {weight:+.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig = exp.as_pyplot_figure(label=predicted_class_idx)\n",
    "    plt.title(f\"LIME - {row.get('job_role_name', 'N/A')} √ó {row.get('skill_name', 'N/A')}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c653295",
   "metadata": {},
   "source": [
    "## 6. Extraction des signaux cl√©s pour explications simplifi√©es\n",
    "\n",
    "Mapper les signaux (trend_score, scarcity_index, internal_usage) vers des phrases simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f650aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_features_from_shap(shap_values_array, feature_names, top_n=3):\n",
    "    \"\"\"\n",
    "    Extrait les top N features qui ont le plus contribu√© √† la pr√©diction.\n",
    "    Retourne une liste de tuples (feature_name, shap_value).\n",
    "    \"\"\"\n",
    "    # Valeurs absolues pour importance\n",
    "    abs_values = np.abs(shap_values_array)\n",
    "    top_indices = np.argsort(abs_values)[-top_n:][::-1]\n",
    "    \n",
    "    return [\n",
    "        (feature_names[idx], shap_values_array[idx])\n",
    "        for idx in top_indices\n",
    "    ]\n",
    "\n",
    "def generate_simple_explanation(top_features, prediction_level):\n",
    "    \"\"\"\n",
    "    G√©n√®re une explication textuelle simple √† partir des top features.\n",
    "    \"\"\"\n",
    "    # Mapping des features vers des termes compr√©hensibles\n",
    "    feature_mapping = {\n",
    "        'trend_score': 'tendance march√©',\n",
    "        'scarcity_index': 'raret√© interne',\n",
    "        'internal_usage': 'usage interne actuel',\n",
    "        'training_requests': 'demandes de formation',\n",
    "        'hiring_difficulty': 'difficult√© de recrutement',\n",
    "        'avg_salary_k': 'niveau de salaire',\n",
    "        'economic_indicator': 'indicateur √©conomique',\n",
    "    }\n",
    "    \n",
    "    explanation_parts = []\n",
    "    \n",
    "    for feat_name, shap_val in top_features:\n",
    "        # Identifier le signal principal\n",
    "        base_feature = None\n",
    "        for key in feature_mapping.keys():\n",
    "            if key in feat_name.lower():\n",
    "                base_feature = key\n",
    "                break\n",
    "        \n",
    "        if base_feature:\n",
    "            readable_name = feature_mapping[base_feature]\n",
    "            \n",
    "            if shap_val > 0:\n",
    "                strength = \"forte\" if abs(shap_val) > 0.2 else \"mod√©r√©e\"\n",
    "                explanation_parts.append(f\"{readable_name} {strength}\")\n",
    "            else:\n",
    "                strength = \"faible\" if abs(shap_val) > 0.2 else \"limit√©e\"\n",
    "                explanation_parts.append(f\"{readable_name} {strength}\")\n",
    "    \n",
    "    if prediction_level == \"HIGH\":\n",
    "        prefix = \"Score √©lev√© car :\"\n",
    "    elif prediction_level == \"MEDIUM\":\n",
    "        prefix = \"Score mod√©r√© car :\"\n",
    "    else:\n",
    "        prefix = \"Score faible car :\"\n",
    "    \n",
    "    if explanation_parts:\n",
    "        return f\"{prefix} {' + '.join(explanation_parts)}\"\n",
    "    else:\n",
    "        return f\"{prefix} multiple facteurs combin√©s\"\n",
    "\n",
    "print(\"‚úÖ Fonctions d'extraction cr√©√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e284c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer des explications simplifi√©es pour nos exemples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù EXPLICATIONS SIMPLIFI√âES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, (idx, row) in enumerate(examples.iterrows()):\n",
    "    pred_proba = clf.predict_proba(X_examples_transformed[i:i+1])[0]\n",
    "    predicted_class_idx = np.argmax(pred_proba)\n",
    "    predicted_level = clf.classes_[predicted_class_idx]\n",
    "    \n",
    "    # Extraire top features\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_vals = shap_values[predicted_class_idx][i]\n",
    "    else:\n",
    "        shap_vals = shap_values[i]\n",
    "    \n",
    "    top_features = extract_top_features_from_shap(shap_vals, feature_names, top_n=3)\n",
    "    explanation = generate_simple_explanation(top_features, predicted_level)\n",
    "    \n",
    "    print(f\"\\nüìå Exemple {i+1}:\")\n",
    "    print(f\"   Job Role: {row.get('job_role_name', 'N/A')}\")\n",
    "    print(f\"   Skill: {row.get('skill_name', 'N/A')}\")\n",
    "    print(f\"   Niveau pr√©dit: {predicted_level} ({pred_proba[predicted_class_idx]:.1%})\")\n",
    "    print(f\"\\n   üí° EXPLICATION:\")\n",
    "    print(f\"   {explanation}\")\n",
    "    print(f\"\\n   üîç D√©tails:\")\n",
    "    for feat, val in top_features:\n",
    "        print(f\"     ‚Ä¢ {feat}: {val:+.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40765b88",
   "metadata": {},
   "source": [
    "## 7. Analyse globale: Features les plus importantes\n",
    "\n",
    "Identifier quelles features sont g√©n√©ralement les plus influentes pour toutes les pr√©dictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer SHAP values pour un √©chantillon plus large\n",
    "sample_for_global = min(500, len(X_transformed))\n",
    "X_global_sample = X_transformed[:sample_for_global]\n",
    "\n",
    "print(f\"Calcul des SHAP values pour {sample_for_global} exemples...\")\n",
    "shap_values_global = explainer.shap_values(X_global_sample)\n",
    "print(\"‚úÖ Calcul termin√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot: importance moyenne des features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä Feature Importance Globale (SHAP)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "if isinstance(shap_values_global, list):\n",
    "    for class_idx, class_name in enumerate(clf.classes_):\n",
    "        print(f\"\\nüéØ Classe: {class_name}\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_global[class_idx],\n",
    "            X_global_sample,\n",
    "            feature_names=feature_names,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            max_display=10\n",
    "        )\n",
    "        plt.title(f\"Top 10 Features - {class_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(\n",
    "        shap_values_global,\n",
    "        X_global_sample,\n",
    "        feature_names=feature_names,\n",
    "        plot_type=\"bar\",\n",
    "        show=False,\n",
    "        max_display=10\n",
    "    )\n",
    "    plt.title(\"Top 10 Features Globales\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddeb8ba",
   "metadata": {},
   "source": [
    "## 8. Conclusions et recommandations\n",
    "\n",
    "### Insights cl√©s:\n",
    "\n",
    "1. **Features les plus influentes**: Les analyses SHAP/LIME r√©v√®lent quelles caract√©ristiques (trend_score, scarcity_index, etc.) contribuent le plus aux pr√©dictions HIGH vs LOW.\n",
    "\n",
    "2. **Patterns par classe**: \n",
    "   - **HIGH**: G√©n√©ralement associ√© √† une forte tendance march√© + raret√© interne √©lev√©e\n",
    "   - **MEDIUM**: Mix √©quilibr√© de signaux\n",
    "   - **LOW**: Tendances faibles ou usage interne d√©j√† satisfaisant\n",
    "\n",
    "3. **Explications simplifi√©es**: Les explications textuelles peuvent √™tre g√©n√©r√©es automatiquement et stock√©es avec les pr√©dictions.\n",
    "\n",
    "### Prochaines √©tapes:\n",
    "\n",
    "- ‚úÖ Cr√©er un module `explanation_engine.py` pour automatiser la g√©n√©ration d'explications\n",
    "- ‚úÖ Ajouter un champ `explanation` au mod√®le `FutureSkillPrediction`\n",
    "- ‚úÖ Int√©grer l'explication dans l'API (optionnel via param√®tre `?include_explanation=true`)\n",
    "- ‚úÖ Documenter l'UI future pour afficher \"Pourquoi cette comp√©tence ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALYSE D'EXPLICABILIT√â TERMIN√âE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nLes visualisations et explications ci-dessus d√©montrent:\")\n",
    "print(\"  1. Comment SHAP identifie les features cl√©s pour chaque pr√©diction\")\n",
    "print(\"  2. Comment LIME fournit des explications locales alternatives\")\n",
    "print(\"  3. Comment traduire les SHAP values en explications textuelles simples\")\n",
    "print(\"\\nCes analyses peuvent √™tre int√©gr√©es dans l'application pour fournir\")\n",
    "print(\"de la transparence aux utilisateurs RH sur les recommandations ML.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
